

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../../">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>lukasz_sawala_bsc_thesis.transfer_eval_main &mdash; UDRL transformer 25/06/2025 documentation</title>
      <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="../../_static/css/theme.css?v=e59714d7" />

  
      <script src="../../_static/jquery.js?v=5d32c60e"></script>
      <script src="../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../../_static/documentation_options.js?v=95f8d375"></script>
      <script src="../../_static/doctools.js?v=9bcbadda"></script>
      <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../index.html" class="icon icon-home">
            UDRL transformer
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../modules.html">lukasz_sawala_bsc_thesis</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">UDRL transformer</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../index.html">Module code</a></li>
      <li class="breadcrumb-item active">lukasz_sawala_bsc_thesis.transfer_eval_main</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <h1>Source code for lukasz_sawala_bsc_thesis.transfer_eval_main</h1><div class="highlight"><pre>
<span></span><span class="kn">import</span><span class="w"> </span><span class="nn">gymnasium</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">gym</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">gymnasium_robotics</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">scipy.stats</span><span class="w"> </span><span class="kn">import</span> <span class="n">sem</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoConfig</span><span class="p">,</span> <span class="n">AutoModel</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">nn</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">models</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">AntNNPretrainedMazePolicy</span><span class="p">,</span>
    <span class="n">AntBERTPretrainedMazePolicy</span><span class="p">,</span>
    <span class="n">AntMazeBERTPretrainedMazeWrapper</span><span class="p">,</span> <span class="n">AntMazeNNPretrainedMazeWrapper</span><span class="p">,</span>
    <span class="n">HugeNeuralNet</span><span class="p">,</span> <span class="n">NeuralNetResNorm</span>
<span class="p">)</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">model_evaluation</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">load_nn_model_for_eval</span><span class="p">,</span> <span class="n">load_bert_mlp_model_for_eval</span><span class="p">,</span>
    <span class="n">NN_MODEL_PATH</span><span class="p">,</span> <span class="n">BERT_MLP_MODEL_PATH</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">utils</span><span class="w"> </span><span class="kn">import</span> <span class="n">parse_arguments</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">model_evaluation</span><span class="w"> </span><span class="kn">import</span> <span class="n">plot_average_rewards</span><span class="p">,</span> <span class="n">print_available_antmaze_envs</span>

<span class="n">DEVICE</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span><span class="p">)</span>

<span class="n">ANTMAZE_BERT_PATH</span> <span class="o">=</span> <span class="s2">&quot;../models/antmaze_tiny-18_512.pth&quot;</span>  <span class="c1"># condition 3</span>
<span class="n">ANTMAZE_NN_PATH</span> <span class="o">=</span> <span class="s2">&quot;../models/antmaze_NN-18_512.pth&quot;</span>  <span class="c1"># condition 3</span>

<span class="c1"># ANTMAZE_BERT_PATH = &quot;antmazeMERGEDinit_tiny-18_512&quot;  # condition 4</span>
<span class="c1"># ANTMAZE_NN_PATH = &quot;antmazeMERGEDinit_NN-18_512&quot;  # condition 4</span>


<div class="viewcode-block" id="load_antmaze_nn_model_for_eval">
<a class="viewcode-back" href="../../lukasz_sawala_bsc_thesis.html#lukasz_sawala_bsc_thesis.transfer_eval_main.load_antmaze_nn_model_for_eval">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">load_antmaze_nn_model_for_eval</span><span class="p">(</span><span class="n">checkpoint_path</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">device</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">initialize_from_scratch</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">NeuralNetResNorm</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Loads the AntMaze NN model components for evaluation.</span>
<span class="sd">    Args:</span>
<span class="sd">        checkpoint_path (str): The path to the checkpoint file.</span>
<span class="sd">        device (str): The device to load the model on.</span>
<span class="sd">    Returns:</span>
<span class="sd">        nn_base (NeuralNet): The loaded model.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">nn_base</span> <span class="o">=</span> <span class="n">NeuralNetResNorm</span><span class="p">(</span><span class="n">input_size</span><span class="o">=</span><span class="mi">31</span><span class="p">,</span> <span class="n">hidden_size</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span> <span class="n">output_size</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">num_layers</span><span class="o">=</span><span class="mi">18</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">initialize_from_scratch</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">nn_base</span>
    <span class="c1"># Load weights</span>
    <span class="n">checkpoint</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">checkpoint_path</span><span class="p">,</span> <span class="n">map_location</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
    <span class="n">nn_base</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">[</span><span class="s2">&quot;nn&quot;</span><span class="p">])</span>

    <span class="c1"># Set models to evaluation mode</span>
    <span class="n">nn_base</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>

    <span class="k">return</span> <span class="n">nn_base</span></div>



<div class="viewcode-block" id="load_antmaze_bertmlp_model_for_eval">
<a class="viewcode-back" href="../../lukasz_sawala_bsc_thesis.html#lukasz_sawala_bsc_thesis.transfer_eval_main.load_antmaze_bertmlp_model_for_eval">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">load_antmaze_bertmlp_model_for_eval</span><span class="p">(</span><span class="n">checkpoint_path</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">device</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">initialize_from_scratch</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Loads the AntMaze BERT MLP model components for evaluation.</span>
<span class="sd">    Returns:</span>
<span class="sd">        model_bert (AutoModel): The loaded BERT model.</span>
<span class="sd">        state_encoder (nn.Linear): The loaded state encoder.</span>
<span class="sd">        mlp (NeuralNet): The loaded MLP model.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">config</span> <span class="o">=</span> <span class="n">AutoConfig</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;prajjwal1/bert-tiny&quot;</span><span class="p">)</span>
    <span class="n">config</span><span class="o">.</span><span class="n">vocab_size</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="n">config</span><span class="o">.</span><span class="n">max_position_embeddings</span> <span class="o">=</span> <span class="mi">1</span>

    <span class="c1"># Initialize components</span>
    <span class="n">model_bert</span> <span class="o">=</span> <span class="n">AutoModel</span><span class="o">.</span><span class="n">from_config</span><span class="p">(</span><span class="n">config</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="n">state_encoder</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">27</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

    <span class="c1"># hidden size + 4 for d_r, d_h and x y values of the goal vector</span>
    <span class="n">mlp</span> <span class="o">=</span> <span class="n">NeuralNetResNorm</span><span class="p">(</span><span class="n">input_size</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">hidden_size</span> <span class="o">+</span> <span class="mi">4</span><span class="p">,</span> <span class="n">hidden_size</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span> <span class="n">output_size</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">num_layers</span><span class="o">=</span><span class="mi">18</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">initialize_from_scratch</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">model_bert</span><span class="p">,</span> <span class="n">state_encoder</span><span class="p">,</span> <span class="n">mlp</span>

    <span class="c1"># Load weights</span>
    <span class="n">checkpoint</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">checkpoint_path</span><span class="p">,</span> <span class="n">map_location</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
    <span class="n">model_bert</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">[</span><span class="s2">&quot;bert&quot;</span><span class="p">])</span>
    <span class="n">state_encoder</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">[</span><span class="s2">&quot;state&quot;</span><span class="p">])</span>
    <span class="n">mlp</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">[</span><span class="s2">&quot;mlp&quot;</span><span class="p">])</span>

    <span class="c1"># Set models to evaluation mode</span>
    <span class="n">model_bert</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    <span class="n">state_encoder</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    <span class="n">mlp</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>

    <span class="k">return</span> <span class="n">model_bert</span><span class="p">,</span> <span class="n">state_encoder</span><span class="p">,</span> <span class="n">mlp</span></div>



<div class="viewcode-block" id="extract_goal_direction">
<a class="viewcode-back" href="../../lukasz_sawala_bsc_thesis.html#lukasz_sawala_bsc_thesis.transfer_eval_main.extract_goal_direction">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">extract_goal_direction</span><span class="p">(</span><span class="n">obs</span><span class="p">:</span> <span class="nb">dict</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Calculate the direction vector from the current position to the goal position.</span>

<span class="sd">    Parameters:</span>
<span class="sd">        obs (dict): A dictionary containing &#39;desired_goal&#39; and &#39;achieved_goal&#39; keys,</span>
<span class="sd">                    where each key maps to a tuple of (x, y) coordinates.</span>

<span class="sd">    Returns:</span>
<span class="sd">        numpy.ndarray: A 2D numpy array representing the direction vector (dx, dy),</span>
<span class="sd">                       where dx and dy are the differences in the x and y coordinates</span>
<span class="sd">                       between the goal and the current position respectively.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">goal_x</span><span class="p">,</span> <span class="n">goal_y</span> <span class="o">=</span> <span class="n">obs</span><span class="p">[</span><span class="s1">&#39;desired_goal&#39;</span><span class="p">]</span>
    <span class="n">current_x</span><span class="p">,</span> <span class="n">current_y</span> <span class="o">=</span> <span class="n">obs</span><span class="p">[</span><span class="s1">&#39;achieved_goal&#39;</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">goal_x</span> <span class="o">-</span> <span class="n">current_x</span><span class="p">,</span> <span class="n">goal_y</span> <span class="o">-</span> <span class="n">current_y</span><span class="p">])</span></div>



<div class="viewcode-block" id="antmaze_evaluate">
<a class="viewcode-back" href="../../lukasz_sawala_bsc_thesis.html#lukasz_sawala_bsc_thesis.transfer_eval_main.antmaze_evaluate">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">antmaze_evaluate</span><span class="p">(</span>
    <span class="n">env</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">episodes</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">time_interval</span><span class="o">=</span><span class="mf">0.05</span><span class="p">,</span> <span class="n">d_r</span><span class="o">=</span><span class="mf">5.0</span><span class="p">,</span> <span class="n">d_h</span><span class="o">=</span><span class="mf">1000.0</span><span class="p">,</span> <span class="n">state_dim</span><span class="o">=</span><span class="mi">105</span><span class="p">,</span> <span class="n">use_goal</span><span class="o">=</span><span class="kc">False</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Evaluate a single given model in the AntMaze environment.</span>

<span class="sd">    Parameters:</span>
<span class="sd">        env (gym.Env): The AntMaze environment.</span>
<span class="sd">        model: The model to evaluate (wrapped to accept multiple input variables).</span>
<span class="sd">        episodes (int): The number of episodes to run for each condition.</span>
<span class="sd">        time_interval (float): Time to sleep between steps when rendering the environment.</span>
<span class="sd">        d_r (float): The desired reward.</span>
<span class="sd">        d_h (float): The desired horizon.</span>
<span class="sd">        state_dim (int): The number of dimensions in the state vector.</span>
<span class="sd">        use_goal (bool): Whether to use the goal direction in the model.</span>

<span class="sd">    Returns:</span>
<span class="sd">        obtained_returns (list): A list of the total rewards obtained in each episode.</span>
<span class="sd">        best_distances (list): A list of the minimum distances to the goal achieved in each episode.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">best_distances</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">obtained_returns</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">episode</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">episodes</span><span class="p">):</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Episode: </span><span class="si">{</span><span class="n">episode</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">obs</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">reset</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>  <span class="c1"># extract the values from the wrapped array</span>
        <span class="c1"># print(obs)</span>
        <span class="n">done</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="n">d_h_copy</span><span class="p">,</span> <span class="n">d_r_copy</span> <span class="o">=</span> <span class="n">d_h</span><span class="p">,</span> <span class="n">d_r</span>
        <span class="n">best_distance</span> <span class="o">=</span> <span class="mi">1000</span>
        <span class="n">total_reward</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">while</span> <span class="ow">not</span> <span class="n">done</span> <span class="ow">and</span> <span class="n">d_h_copy</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>

            <span class="n">goal_vec</span> <span class="o">=</span> <span class="n">extract_goal_direction</span><span class="p">(</span><span class="n">obs</span><span class="p">)</span>
            <span class="n">distance</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">goal_vec</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">distance</span> <span class="o">&lt;</span> <span class="n">best_distance</span><span class="p">:</span>
                <span class="n">best_distance</span> <span class="o">=</span> <span class="n">distance</span>

            <span class="n">obs</span> <span class="o">=</span> <span class="n">obs</span><span class="p">[</span><span class="s2">&quot;observation&quot;</span><span class="p">][:</span><span class="n">state_dim</span><span class="p">]</span>  <span class="c1"># exytract the values from the wrapped array</span>

            <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
                <span class="n">action_tensor</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">obs</span><span class="p">,</span> <span class="n">d_r_copy</span><span class="p">,</span> <span class="n">d_h_copy</span><span class="p">,</span> <span class="n">goal_vec</span><span class="p">,</span> <span class="n">DEVICE</span><span class="p">,</span> <span class="n">use_goal</span><span class="o">=</span><span class="n">use_goal</span><span class="p">)</span>
            <span class="n">action</span> <span class="o">=</span> <span class="n">action_tensor</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>

            <span class="n">obs</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">terminated</span><span class="p">,</span> <span class="n">truncated</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">action</span><span class="p">)</span>
            <span class="n">total_reward</span> <span class="o">+=</span> <span class="n">reward</span>
            <span class="n">d_r_copy</span> <span class="o">-=</span> <span class="n">reward</span>
            <span class="n">d_h_copy</span> <span class="o">-=</span> <span class="mi">1</span>
            <span class="n">done</span> <span class="o">=</span> <span class="n">terminated</span> <span class="ow">or</span> <span class="n">truncated</span>

            <span class="c1"># env.render()    # uncomment this if you want to see the environment</span>
            <span class="c1"># time.sleep(time_interval)</span>
        <span class="n">obtained_returns</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">total_reward</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">best_distance</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;goal reached!&quot;</span><span class="p">)</span>
        <span class="n">best_distances</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">best_distance</span><span class="p">)</span>
        <span class="c1"># print(f&quot;Episode {episode} finished with total reward: {total_reward}, best distance: {best_distance}&quot;)</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;minimum return:&quot;</span><span class="p">,</span> <span class="nb">min</span><span class="p">(</span><span class="n">obtained_returns</span><span class="p">),</span> <span class="s2">&quot;maximum return:&quot;</span><span class="p">,</span> <span class="nb">max</span><span class="p">(</span><span class="n">obtained_returns</span><span class="p">),</span> <span class="s2">&quot;average return:&quot;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">obtained_returns</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">obtained_returns</span><span class="p">,</span> <span class="n">best_distances</span></div>



<div class="viewcode-block" id="transfer_eval_main">
<a class="viewcode-back" href="../../lukasz_sawala_bsc_thesis.html#lukasz_sawala_bsc_thesis.transfer_eval_main.transfer_eval_main">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">transfer_eval_main</span><span class="p">(</span><span class="n">args</span><span class="p">):</span>
    <span class="n">gym</span><span class="o">.</span><span class="n">register_envs</span><span class="p">(</span><span class="n">gymnasium_robotics</span><span class="p">)</span>
    <span class="c1"># print_available_antmaze_envs() # check whether its compatible</span>
    <span class="n">env</span> <span class="o">=</span> <span class="n">gym</span><span class="o">.</span><span class="n">make</span><span class="p">(</span><span class="s2">&quot;AntMaze_MediumDense-v5&quot;</span><span class="p">)</span>  <span class="c1"># ALTENRATIVE: &quot;AntMaze_Medium_Diverse_GR-v4&quot; # render mode human to see whats up</span>

    <span class="c1"># --- load models and wrap them to accept goal locations if necessary ------</span>
    <span class="k">if</span> <span class="n">args</span><span class="p">[</span><span class="s2">&quot;model_type&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;NeuralNet&quot;</span><span class="p">:</span>
        <span class="n">nn_base</span><span class="p">,</span> <span class="n">actionhead</span> <span class="o">=</span> <span class="n">load_nn_model_for_eval</span><span class="p">(</span><span class="mi">107</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="n">NN_MODEL_PATH</span><span class="p">,</span> <span class="n">DEVICE</span><span class="p">)</span>
        <span class="n">model</span> <span class="o">=</span> <span class="n">AntNNPretrainedMazePolicy</span><span class="p">(</span><span class="n">nn_base</span><span class="p">,</span> <span class="n">action_dim</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">adjusted_head</span><span class="o">=</span><span class="n">actionhead</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">DEVICE</span><span class="p">)</span>
        <span class="n">use_goal</span> <span class="o">=</span> <span class="kc">True</span> <span class="k">if</span> <span class="s2">&quot;finetuned&quot;</span> <span class="ow">in</span> <span class="n">NN_MODEL_PATH</span> <span class="k">else</span> <span class="kc">False</span>
        <span class="n">state_dim</span> <span class="o">=</span> <span class="mi">105</span>
    <span class="k">elif</span> <span class="n">args</span><span class="p">[</span><span class="s2">&quot;model_type&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;BERT_MLP&quot;</span><span class="p">:</span>
        <span class="k">if</span> <span class="s2">&quot;finetuned&quot;</span> <span class="ow">in</span> <span class="n">BERT_MLP_MODEL_PATH</span><span class="p">:</span>
            <span class="n">bert_base</span> <span class="o">=</span> <span class="n">load_bert_mlp_model_for_eval</span><span class="p">(</span><span class="n">BERT_MLP_MODEL_PATH</span><span class="p">,</span> <span class="n">DEVICE</span><span class="p">,</span> <span class="n">antmaze_pretrained</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="n">model</span> <span class="o">=</span> <span class="n">AntBERTPretrainedMazePolicy</span><span class="p">(</span><span class="o">*</span><span class="n">bert_base</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">3</span><span class="p">],</span> <span class="n">init_head</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">adjusted_head</span><span class="o">=</span><span class="n">bert_base</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span> <span class="n">hidden_size</span><span class="o">=</span><span class="mi">512</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">DEVICE</span><span class="p">)</span>
            <span class="n">use_goal</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">bert_base</span> <span class="o">=</span> <span class="n">load_bert_mlp_model_for_eval</span><span class="p">(</span><span class="n">BERT_MLP_MODEL_PATH</span><span class="p">,</span> <span class="n">DEVICE</span><span class="p">)</span>
            <span class="n">model</span> <span class="o">=</span> <span class="n">AntBERTPretrainedMazePolicy</span><span class="p">(</span><span class="o">*</span><span class="n">bert_base</span><span class="p">,</span> <span class="n">init_head</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">DEVICE</span><span class="p">)</span>
            <span class="n">use_goal</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="n">state_dim</span> <span class="o">=</span> <span class="mi">105</span>
    <span class="k">elif</span> <span class="n">args</span><span class="p">[</span><span class="s2">&quot;model_type&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;ANTMAZE_BERT_MLP&quot;</span><span class="p">:</span>
        <span class="n">model_path</span> <span class="o">=</span> <span class="n">args</span><span class="p">[</span><span class="s2">&quot;model_path&quot;</span><span class="p">]</span> <span class="k">if</span> <span class="s2">&quot;model_path&quot;</span> <span class="ow">in</span> <span class="n">args</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span> <span class="k">else</span> <span class="n">ANTMAZE_BERT_PATH</span>
        <span class="n">model_components</span> <span class="o">=</span> <span class="n">load_antmaze_bertmlp_model_for_eval</span><span class="p">(</span><span class="n">model_path</span><span class="p">,</span> <span class="n">DEVICE</span><span class="p">)</span>
        <span class="n">model</span> <span class="o">=</span> <span class="n">AntMazeBERTPretrainedMazeWrapper</span><span class="p">(</span><span class="o">*</span><span class="n">model_components</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">DEVICE</span><span class="p">)</span>
        <span class="n">state_dim</span> <span class="o">=</span> <span class="mi">27</span>  <span class="c1"># reduced state space due to dataset mismatch</span>
        <span class="n">use_goal</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="k">elif</span> <span class="n">args</span><span class="p">[</span><span class="s2">&quot;model_type&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;ANTMAZE_NN&quot;</span><span class="p">:</span>
        <span class="n">model_path</span> <span class="o">=</span> <span class="n">args</span><span class="p">[</span><span class="s2">&quot;model_path&quot;</span><span class="p">]</span> <span class="k">if</span> <span class="s2">&quot;model_path&quot;</span> <span class="ow">in</span> <span class="n">args</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span> <span class="k">else</span> <span class="n">ANTMAZE_NN_PATH</span>
        <span class="n">model</span> <span class="o">=</span> <span class="n">load_antmaze_nn_model_for_eval</span><span class="p">(</span><span class="n">model_path</span><span class="p">,</span> <span class="n">DEVICE</span><span class="p">)</span>
        <span class="n">model</span> <span class="o">=</span> <span class="n">AntMazeNNPretrainedMazeWrapper</span><span class="p">(</span><span class="n">model</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">DEVICE</span><span class="p">)</span>
        <span class="n">state_dim</span> <span class="o">=</span> <span class="mi">27</span>  <span class="c1"># reduced state space due to dataset mismatch</span>
        <span class="n">use_goal</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unsupported model_type: </span><span class="si">{</span><span class="n">args</span><span class="p">[</span><span class="s1">&#39;model_type&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="n">d_h</span> <span class="o">=</span> <span class="mf">1000.0</span>
    <span class="n">d_r_options</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span> <span class="o">*</span> <span class="mi">50</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">args</span><span class="p">[</span><span class="s2">&quot;d_r_array_length&quot;</span><span class="p">])]</span>
    <span class="n">num_episodes</span> <span class="o">=</span> <span class="n">args</span><span class="p">[</span><span class="s2">&quot;episodes&quot;</span><span class="p">]</span>
    <span class="n">average_rewards</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">sem_values</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">success_rates</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Evaluating AntMaze with model:&quot;</span><span class="p">,</span> <span class="n">args</span><span class="p">[</span><span class="s2">&quot;model_type&quot;</span><span class="p">])</span>

    <span class="k">for</span> <span class="n">d_r</span> <span class="ow">in</span> <span class="n">d_r_options</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">50</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Trying with d_r:&quot;</span><span class="p">,</span> <span class="n">d_r</span><span class="p">)</span>
        <span class="n">returns</span><span class="p">,</span> <span class="n">distances</span> <span class="o">=</span> <span class="n">antmaze_evaluate</span><span class="p">(</span>
            <span class="n">env</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">episodes</span><span class="o">=</span><span class="n">num_episodes</span><span class="p">,</span> <span class="n">d_r</span><span class="o">=</span><span class="n">d_r</span><span class="p">,</span> <span class="n">d_h</span><span class="o">=</span><span class="n">d_h</span><span class="p">,</span>
            <span class="n">time_interval</span><span class="o">=</span><span class="mf">0.005</span><span class="p">,</span> <span class="n">state_dim</span><span class="o">=</span><span class="n">state_dim</span><span class="p">,</span> <span class="n">use_goal</span><span class="o">=</span><span class="n">use_goal</span><span class="p">)</span>
        <span class="n">average_rewards</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">returns</span><span class="p">))</span>
        <span class="n">sem_values</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">sem</span><span class="p">(</span><span class="n">returns</span><span class="p">))</span>
        <span class="n">success_rates</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">([</span><span class="n">d</span> <span class="o">&lt;</span> <span class="mi">1</span> <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="n">distances</span><span class="p">]))</span>

    <span class="n">save_path</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;antmaze_</span><span class="si">{</span><span class="n">args</span><span class="p">[</span><span class="s1">&#39;model_type&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">_d_r_eval_results.png&quot;</span>

    <span class="k">if</span> <span class="s2">&quot;return_without_plotting&quot;</span> <span class="ow">in</span> <span class="n">args</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span> <span class="ow">and</span> <span class="n">args</span><span class="p">[</span><span class="s2">&quot;return_without_plotting&quot;</span><span class="p">]:</span>
        <span class="k">return</span> <span class="n">average_rewards</span><span class="p">,</span> <span class="n">sem_values</span><span class="p">,</span> <span class="n">success_rates</span>

    <span class="n">plot_average_rewards</span><span class="p">(</span><span class="n">average_rewards</span><span class="p">,</span> <span class="n">sem_values</span><span class="p">,</span> <span class="n">d_r_options</span><span class="p">,</span>
                         <span class="n">title</span><span class="o">=</span><span class="s2">&quot;Average Reward vs. d_r&quot;</span><span class="p">,</span> <span class="n">save_path</span><span class="o">=</span><span class="n">save_path</span><span class="p">,</span>
                         <span class="n">max_y</span><span class="o">=</span><span class="nb">max</span><span class="p">(</span><span class="n">d_r_options</span><span class="p">)</span> <span class="o">*</span> <span class="mf">1.1</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;success rates: &quot;</span><span class="p">,</span> <span class="n">success_rates</span><span class="p">,</span> <span class="s2">&quot;average:&quot;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">success_rates</span><span class="p">))</span></div>



<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="n">args</span> <span class="o">=</span> <span class="n">parse_arguments</span><span class="p">(</span><span class="n">training</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">transfer_eval_main</span><span class="p">(</span><span class="n">args</span><span class="p">)</span>
</pre></div>

           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2025, Lukasz Sawala.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>