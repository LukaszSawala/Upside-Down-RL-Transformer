Using device: cuda
Creating a model: finetunedbroski-512.pth

Running grid search with BATCH_SIZE=128, LEARNING_RATE=0.0001, EPOCHS=100
Freezing base model parameters
Epoch 1/100 [Train]: Starting...
Epoch 1/100 [Val  ]: Starting...
Epoch 1/100: Train Loss = 0.2041, Val Loss = 0.1790
Best model found! Validation Loss: 0.1790
Epoch 2/100 [Train]: Starting...
Epoch 2/100 [Val  ]: Starting...
Epoch 2/100: Train Loss = 0.1825, Val Loss = 0.1726
Best model found! Validation Loss: 0.1726
Epoch 3/100 [Train]: Starting...
Epoch 3/100 [Val  ]: Starting...
Epoch 3/100: Train Loss = 0.1758, Val Loss = 0.1671
Best model found! Validation Loss: 0.1671
Epoch 4/100 [Train]: Starting...
Epoch 4/100 [Val  ]: Starting...
Epoch 4/100: Train Loss = 0.1718, Val Loss = 0.1641
Best model found! Validation Loss: 0.1641
Epoch 5/100 [Train]: Starting...
Epoch 5/100 [Val  ]: Starting...
Epoch 5/100: Train Loss = 0.1690, Val Loss = 0.1617
Best model found! Validation Loss: 0.1617
Epoch 6/100 [Train]: Starting...
Epoch 6/100 [Val  ]: Starting...
Epoch 6/100: Train Loss = 0.1667, Val Loss = 0.1612
Best model found! Validation Loss: 0.1612
Epoch 7/100 [Train]: Starting...
Epoch 7/100 [Val  ]: Starting...
Epoch 7/100: Train Loss = 0.1650, Val Loss = 0.1579
Best model found! Validation Loss: 0.1579
Epoch 8/100 [Train]: Starting...
Epoch 8/100 [Val  ]: Starting...
Epoch 8/100: Train Loss = 0.1634, Val Loss = 0.1572
Best model found! Validation Loss: 0.1572
Epoch 9/100 [Train]: Starting...
Epoch 9/100 [Val  ]: Starting...
Epoch 9/100: Train Loss = 0.1621, Val Loss = 0.1552
Best model found! Validation Loss: 0.1552
Epoch 10/100 [Train]: Starting...
Epoch 10/100 [Val  ]: Starting...
Epoch 10/100: Train Loss = 0.1609, Val Loss = 0.1552
Epoch 11/100 [Train]: Starting...
Epoch 11/100 [Val  ]: Starting...
Epoch 11/100: Train Loss = 0.1600, Val Loss = 0.1538
Best model found! Validation Loss: 0.1538
Epoch 12/100 [Train]: Starting...
Epoch 12/100 [Val  ]: Starting...
Epoch 12/100: Train Loss = 0.1590, Val Loss = 0.1538
Best model found! Validation Loss: 0.1538
Epoch 13/100 [Train]: Starting...
Epoch 13/100 [Val  ]: Starting...
Epoch 13/100: Train Loss = 0.1582, Val Loss = 0.1523
Best model found! Validation Loss: 0.1523
Epoch 14/100 [Train]: Starting...
Epoch 14/100 [Val  ]: Starting...
Epoch 14/100: Train Loss = 0.1573, Val Loss = 0.1525
Epoch 15/100 [Train]: Starting...
Epoch 15/100 [Val  ]: Starting...
Epoch 15/100: Train Loss = 0.1566, Val Loss = 0.1509
Best model found! Validation Loss: 0.1509
Epoch 16/100 [Train]: Starting...
Epoch 16/100 [Val  ]: Starting...
Epoch 16/100: Train Loss = 0.1560, Val Loss = 0.1503
Best model found! Validation Loss: 0.1503
Epoch 17/100 [Train]: Starting...
Epoch 17/100 [Val  ]: Starting...
Epoch 17/100: Train Loss = 0.1554, Val Loss = 0.1501
Best model found! Validation Loss: 0.1501
Epoch 18/100 [Train]: Starting...
Epoch 18/100 [Val  ]: Starting...
Epoch 18/100: Train Loss = 0.1547, Val Loss = 0.1496
Best model found! Validation Loss: 0.1496
Epoch 19/100 [Train]: Starting...
Epoch 19/100 [Val  ]: Starting...
Epoch 19/100: Train Loss = 0.1542, Val Loss = 0.1501
Epoch 20/100 [Train]: Starting...
Epoch 20/100 [Val  ]: Starting...
Epoch 20/100: Train Loss = 0.1537, Val Loss = 0.1495
Best model found! Validation Loss: 0.1495
Epoch 21/100 [Train]: Starting...
Epoch 21/100 [Val  ]: Starting...
Epoch 21/100: Train Loss = 0.1533, Val Loss = 0.1503
Epoch 22/100 [Train]: Starting...
Epoch 22/100 [Val  ]: Starting...
Epoch 22/100: Train Loss = 0.1528, Val Loss = 0.1487
Best model found! Validation Loss: 0.1487
Epoch 23/100 [Train]: Starting...
Epoch 23/100 [Val  ]: Starting...
Epoch 23/100: Train Loss = 0.1522, Val Loss = 0.1488
Epoch 24/100 [Train]: Starting...
Epoch 24/100 [Val  ]: Starting...
Epoch 24/100: Train Loss = 0.1520, Val Loss = 0.1485
Best model found! Validation Loss: 0.1485
Epoch 25/100 [Train]: Starting...
Epoch 25/100 [Val  ]: Starting...
Epoch 25/100: Train Loss = 0.1514, Val Loss = 0.1493
Epoch 26/100 [Train]: Starting...
Epoch 26/100 [Val  ]: Starting...
Epoch 26/100: Train Loss = 0.1510, Val Loss = 0.1472
Best model found! Validation Loss: 0.1472
Epoch 27/100 [Train]: Starting...
Epoch 27/100 [Val  ]: Starting...
Epoch 27/100: Train Loss = 0.1507, Val Loss = 0.1471
Best model found! Validation Loss: 0.1471
Epoch 28/100 [Train]: Starting...
Epoch 28/100 [Val  ]: Starting...
Epoch 28/100: Train Loss = 0.1502, Val Loss = 0.1477
Epoch 29/100 [Train]: Starting...
Epoch 29/100 [Val  ]: Starting...
Epoch 29/100: Train Loss = 0.1499, Val Loss = 0.1482
Epoch 30/100 [Train]: Starting...
Epoch 30/100 [Val  ]: Starting...
Epoch 30/100: Train Loss = 0.1496, Val Loss = 0.1468
Best model found! Validation Loss: 0.1468
Epoch 31/100 [Train]: Starting...
Epoch 31/100 [Val  ]: Starting...
Epoch 31/100: Train Loss = 0.1493, Val Loss = 0.1467
Best model found! Validation Loss: 0.1467
Epoch 32/100 [Train]: Starting...
Epoch 32/100 [Val  ]: Starting...
Epoch 32/100: Train Loss = 0.1489, Val Loss = 0.1463
Best model found! Validation Loss: 0.1463
Epoch 33/100 [Train]: Starting...
Epoch 33/100 [Val  ]: Starting...
Epoch 33/100: Train Loss = 0.1484, Val Loss = 0.1470
Epoch 34/100 [Train]: Starting...
Epoch 34/100 [Val  ]: Starting...
Epoch 34/100: Train Loss = 0.1482, Val Loss = 0.1458
Best model found! Validation Loss: 0.1458
Epoch 35/100 [Train]: Starting...
Epoch 35/100 [Val  ]: Starting...
Epoch 35/100: Train Loss = 0.1479, Val Loss = 0.1459
Epoch 36/100 [Train]: Starting...
Epoch 36/100 [Val  ]: Starting...
Epoch 36/100: Train Loss = 0.1475, Val Loss = 0.1459
Epoch 37/100 [Train]: Starting...
Epoch 37/100 [Val  ]: Starting...
Epoch 37/100: Train Loss = 0.1472, Val Loss = 0.1455
Best model found! Validation Loss: 0.1455
Epoch 38/100 [Train]: Starting...
Epoch 38/100 [Val  ]: Starting...
Epoch 38/100: Train Loss = 0.1468, Val Loss = 0.1463
Epoch 39/100 [Train]: Starting...
Epoch 39/100 [Val  ]: Starting...
Epoch 39/100: Train Loss = 0.1465, Val Loss = 0.1457
Epoch 40/100 [Train]: Starting...
Epoch 40/100 [Val  ]: Starting...
Epoch 40/100: Train Loss = 0.1463, Val Loss = 0.1457
Epoch 41/100 [Train]: Starting...
Epoch 41/100 [Val  ]: Starting...
Epoch 41/100: Train Loss = 0.1460, Val Loss = 0.1451
Best model found! Validation Loss: 0.1451
Epoch 42/100 [Train]: Starting...
Epoch 42/100 [Val  ]: Starting...
Epoch 42/100: Train Loss = 0.1457, Val Loss = 0.1456
Epoch 43/100 [Train]: Starting...
Epoch 43/100 [Val  ]: Starting...
Epoch 43/100: Train Loss = 0.1454, Val Loss = 0.1456
Epoch 44/100 [Train]: Starting...
Epoch 44/100 [Val  ]: Starting...
Epoch 44/100: Train Loss = 0.1451, Val Loss = 0.1452
Epoch 45/100 [Train]: Starting...
Epoch 45/100 [Val  ]: Starting...
Epoch 45/100: Train Loss = 0.1449, Val Loss = 0.1453
Epoch 46/100 [Train]: Starting...
Epoch 46/100 [Val  ]: Starting...
Epoch 46/100: Train Loss = 0.1446, Val Loss = 0.1445
Best model found! Validation Loss: 0.1445
Epoch 47/100 [Train]: Starting...
Epoch 47/100 [Val  ]: Starting...
Epoch 47/100: Train Loss = 0.1443, Val Loss = 0.1450
Epoch 48/100 [Train]: Starting...
Epoch 48/100 [Val  ]: Starting...
Epoch 48/100: Train Loss = 0.1441, Val Loss = 0.1449
Epoch 49/100 [Train]: Starting...
Epoch 49/100 [Val  ]: Starting...
Epoch 49/100: Train Loss = 0.1437, Val Loss = 0.1441
Best model found! Validation Loss: 0.1441
Epoch 50/100 [Train]: Starting...
Epoch 50/100 [Val  ]: Starting...
Epoch 50/100: Train Loss = 0.1434, Val Loss = 0.1441
Best model found! Validation Loss: 0.1441
Epoch 51/100 [Train]: Starting...
Epoch 51/100 [Val  ]: Starting...
Epoch 51/100: Train Loss = 0.1432, Val Loss = 0.1448
Epoch 52/100 [Train]: Starting...
Epoch 52/100 [Val  ]: Starting...
Epoch 52/100: Train Loss = 0.1429, Val Loss = 0.1448
Epoch 53/100 [Train]: Starting...
Epoch 53/100 [Val  ]: Starting...
Epoch 53/100: Train Loss = 0.1427, Val Loss = 0.1450
Epoch 54/100 [Train]: Starting...
Epoch 54/100 [Val  ]: Starting...
Epoch 54/100: Train Loss = 0.1426, Val Loss = 0.1457
Epoch 55/100 [Train]: Starting...
Epoch 55/100 [Val  ]: Starting...
Epoch 55/100: Train Loss = 0.1422, Val Loss = 0.1446
Epoch 56/100 [Train]: Starting...
Epoch 56/100 [Val  ]: Starting...
Epoch 56/100: Train Loss = 0.1420, Val Loss = 0.1444
Epoch 57/100 [Train]: Starting...
Epoch 57/100 [Val  ]: Starting...
Epoch 57/100: Train Loss = 0.1417, Val Loss = 0.1448
Epoch 58/100 [Train]: Starting...
Epoch 58/100 [Val  ]: Starting...
Epoch 58/100: Train Loss = 0.1415, Val Loss = 0.1448
Epoch 59/100 [Train]: Starting...
Epoch 59/100 [Val  ]: Starting...
Epoch 59/100: Train Loss = 0.1410, Val Loss = 0.1445
Epoch 60/100 [Train]: Starting...
Epoch 60/100 [Val  ]: Starting...
Epoch 60/100: Train Loss = 0.1410, Val Loss = 0.1450
Early stopping.
Training complete for BATCH_SIZE=128, LEARNING_RATE=0.0001, EPOCHS=100. Evaluating on test set...
Evaluation: Starting...
Test Loss for config (BATCH_SIZE=128, LEARNING_RATE=0.0001, EPOCHS=100): 0.1459
Model for this configuration saved to finetunedbroski-512.pth
============================================================

Grid Search Complete.
The configuration that yielded the best reported test loss was: BATCH_SIZE=128, LEARNING_RATE=0.0001, EPOCHS=100
Best reported Test Loss during search: 0.1459
The model saved at 'finetunedbroski-512.pth' corresponds to the results of the *last* successfully trained hyperparameter set.

###############################################################################
H치br칩k Cluster
Job 17810231 for user s5173019
Finished at: Fri Jun  6 11:24:52 CEST 2025

Job details:
============

Job ID                         : 17810231
Name                           : jobscript-gpu.sh
User                           : s5173019
Partition                      : gpushort
Nodes                          : v100v2gpu17
Number of Nodes                : 1
Cores                          : 8
Number of Tasks                : 1
State                          : COMPLETED  
Submit                         : 2025-06-06T10:35:34
Start                          : 2025-06-06T10:36:51
End                            : 2025-06-06T11:24:48
Reserved walltime              : 02:00:00
Used walltime                  : 00:47:57
Used CPU time                  : 00:47:08 (Efficiency: 12.29%)
% User (Computation)           : 99.60%
% System (I/O)                 :  0.40%
Total memory reserved          : 8000M
Maximum memory used            : 1.40G
Requested GPUs                 : 1
Allocated GPUs                 : v100=1
Max GPU utilization            : 29%
Max GPU memory used            : 470.00M

Acknowledgements:
=================

Please see this page for information about acknowledging H치br칩k in your publications:

https://wiki.hpc.rug.nl/habrok/introduction/scientific_output

################################################################################
