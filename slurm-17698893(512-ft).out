Using device: cuda
Creating a model: finetunedbroski-512.pth

Running grid search with BATCH_SIZE=16, LEARNING_RATE=1e-05, EPOCHS=60
Freezing base model parameters
Epoch 1/60 [Train]: Starting...
Epoch 1/60 [Val  ]: Starting...
Epoch 1/60: Train Loss = 0.2407, Val Loss = 0.2121
Best model found! Validation Loss: 0.2121
Epoch 2/60 [Train]: Starting...
Epoch 2/60 [Val  ]: Starting...
Epoch 2/60: Train Loss = 0.2071, Val Loss = 0.1967
Best model found! Validation Loss: 0.1967
Epoch 3/60 [Train]: Starting...
Epoch 3/60 [Val  ]: Starting...
Epoch 3/60: Train Loss = 0.1952, Val Loss = 0.1845
Best model found! Validation Loss: 0.1845
Epoch 4/60 [Train]: Starting...
Epoch 4/60 [Val  ]: Starting...
Epoch 4/60: Train Loss = 0.1883, Val Loss = 0.1822
Best model found! Validation Loss: 0.1822
Epoch 5/60 [Train]: Starting...
Epoch 5/60 [Val  ]: Starting...
Epoch 5/60: Train Loss = 0.1838, Val Loss = 0.1772
Best model found! Validation Loss: 0.1772
Epoch 6/60 [Train]: Starting...
Epoch 6/60 [Val  ]: Starting...
Epoch 6/60: Train Loss = 0.1803, Val Loss = 0.1738
Best model found! Validation Loss: 0.1738
Epoch 7/60 [Train]: Starting...
Epoch 7/60 [Val  ]: Starting...
Epoch 7/60: Train Loss = 0.1774, Val Loss = 0.1706
Best model found! Validation Loss: 0.1706
Epoch 8/60 [Train]: Starting...
Epoch 8/60 [Val  ]: Starting...
Epoch 8/60: Train Loss = 0.1750, Val Loss = 0.1683
Best model found! Validation Loss: 0.1683
Epoch 9/60 [Train]: Starting...
Epoch 9/60 [Val  ]: Starting...
Epoch 9/60: Train Loss = 0.1730, Val Loss = 0.1675
Best model found! Validation Loss: 0.1675
Epoch 10/60 [Train]: Starting...
Epoch 10/60 [Val  ]: Starting...
Epoch 10/60: Train Loss = 0.1712, Val Loss = 0.1650
Best model found! Validation Loss: 0.1650
Epoch 11/60 [Train]: Starting...
Epoch 11/60 [Val  ]: Starting...
Epoch 11/60: Train Loss = 0.1697, Val Loss = 0.1629
Best model found! Validation Loss: 0.1629
Epoch 12/60 [Train]: Starting...
Epoch 12/60 [Val  ]: Starting...
Epoch 12/60: Train Loss = 0.1683, Val Loss = 0.1625
Best model found! Validation Loss: 0.1625
Epoch 13/60 [Train]: Starting...
Epoch 13/60 [Val  ]: Starting...
Epoch 13/60: Train Loss = 0.1672, Val Loss = 0.1611
Best model found! Validation Loss: 0.1611
Epoch 14/60 [Train]: Starting...
Epoch 14/60 [Val  ]: Starting...
Epoch 14/60: Train Loss = 0.1661, Val Loss = 0.1601
Best model found! Validation Loss: 0.1601
Epoch 15/60 [Train]: Starting...
Epoch 15/60 [Val  ]: Starting...
Epoch 15/60: Train Loss = 0.1651, Val Loss = 0.1589
Best model found! Validation Loss: 0.1589
Epoch 16/60 [Train]: Starting...
Epoch 16/60 [Val  ]: Starting...
Epoch 16/60: Train Loss = 0.1642, Val Loss = 0.1577
Best model found! Validation Loss: 0.1577
Epoch 17/60 [Train]: Starting...
Epoch 17/60 [Val  ]: Starting...
Epoch 17/60: Train Loss = 0.1635, Val Loss = 0.1578
Epoch 18/60 [Train]: Starting...
Epoch 18/60 [Val  ]: Starting...
Epoch 18/60: Train Loss = 0.1627, Val Loss = 0.1569
Best model found! Validation Loss: 0.1569
Epoch 19/60 [Train]: Starting...
Epoch 19/60 [Val  ]: Starting...
Epoch 19/60: Train Loss = 0.1619, Val Loss = 0.1572
Epoch 20/60 [Train]: Starting...
Epoch 20/60 [Val  ]: Starting...
Epoch 20/60: Train Loss = 0.1613, Val Loss = 0.1560
Best model found! Validation Loss: 0.1560
Epoch 21/60 [Train]: Starting...
Epoch 21/60 [Val  ]: Starting...
Epoch 21/60: Train Loss = 0.1608, Val Loss = 0.1558
Best model found! Validation Loss: 0.1558
Epoch 22/60 [Train]: Starting...
Epoch 22/60 [Val  ]: Starting...
Epoch 22/60: Train Loss = 0.1601, Val Loss = 0.1575
Epoch 23/60 [Train]: Starting...
Epoch 23/60 [Val  ]: Starting...
Epoch 23/60: Train Loss = 0.1596, Val Loss = 0.1540
Best model found! Validation Loss: 0.1540
Epoch 24/60 [Train]: Starting...
Epoch 24/60 [Val  ]: Starting...
Epoch 24/60: Train Loss = 0.1591, Val Loss = 0.1555
Epoch 25/60 [Train]: Starting...
Epoch 25/60 [Val  ]: Starting...
Epoch 25/60: Train Loss = 0.1586, Val Loss = 0.1531
Best model found! Validation Loss: 0.1531
Epoch 26/60 [Train]: Starting...
Epoch 26/60 [Val  ]: Starting...
Epoch 26/60: Train Loss = 0.1581, Val Loss = 0.1538
Epoch 27/60 [Train]: Starting...
Epoch 27/60 [Val  ]: Starting...
Epoch 27/60: Train Loss = 0.1577, Val Loss = 0.1519
Best model found! Validation Loss: 0.1519
Epoch 28/60 [Train]: Starting...
Epoch 28/60 [Val  ]: Starting...
Epoch 28/60: Train Loss = 0.1572, Val Loss = 0.1526
Epoch 29/60 [Train]: Starting...
Epoch 29/60 [Val  ]: Starting...
Epoch 29/60: Train Loss = 0.1568, Val Loss = 0.1525
Epoch 30/60 [Train]: Starting...
Epoch 30/60 [Val  ]: Starting...
Epoch 30/60: Train Loss = 0.1565, Val Loss = 0.1527
Early stopping.
Training complete for BATCH_SIZE=16, LEARNING_RATE=1e-05, EPOCHS=60. Evaluating on test set...
Evaluation: Starting...
Test Loss for config (BATCH_SIZE=16, LEARNING_RATE=1e-05, EPOCHS=60): 0.1534
Model for this configuration saved to finetunedbroski-512.pth
============================================================

Grid Search Complete.
The configuration that yielded the best reported test loss was: BATCH_SIZE=16, LEARNING_RATE=1e-05, EPOCHS=60
Best reported Test Loss during search: 0.1534
The model saved at 'finetunedbroski-512.pth' corresponds to the results of the *last* successfully trained hyperparameter set.

###############################################################################
H치br칩k Cluster
Job 17698893 for user s5173019
Finished at: Fri May 30 19:18:39 CEST 2025

Job details:
============

Job ID                         : 17698893
Name                           : jobscript-gpu.sh
User                           : s5173019
Partition                      : gpushort
Nodes                          : v100v2gpu16
Number of Nodes                : 1
Cores                          : 8
Number of Tasks                : 1
State                          : COMPLETED  
Submit                         : 2025-05-30T17:16:35
Start                          : 2025-05-30T17:30:06
End                            : 2025-05-30T19:18:35
Reserved walltime              : 02:30:00
Used walltime                  : 01:48:29
Used CPU time                  : 01:46:45 (Efficiency: 12.30%)
% User (Computation)           : 99.63%
% System (I/O)                 :  0.37%
Total memory reserved          : 8000M
Maximum memory used            : 1.41G
Requested GPUs                 : 1
Allocated GPUs                 : v100=1
Max GPU utilization            : 27%
Max GPU memory used            : 444.00M

Acknowledgements:
=================

Please see this page for information about acknowledging H치br칩k in your publications:

https://wiki.hpc.rug.nl/habrok/introduction/scientific_output

################################################################################
