Using device: cuda

Running grid search with BATCH_SIZE=16, LEARNING_RATE=5e-05, EPOCHS=30
Freezing base model parameters
Epoch 1/30 [Train]: Starting...
Epoch 1/30 [Val  ]: Starting...
Epoch 1/30: Train Loss = 0.1701, Val Loss = 0.1496
Best model found! Validation Loss: 0.1496
Epoch 2/30 [Train]: Starting...
Epoch 2/30 [Val  ]: Starting...
Epoch 2/30: Train Loss = 0.1473, Val Loss = 0.1409
Best model found! Validation Loss: 0.1409
Epoch 3/30 [Train]: Starting...
Epoch 3/30 [Val  ]: Starting...
Epoch 3/30: Train Loss = 0.1416, Val Loss = 0.1356
Best model found! Validation Loss: 0.1356
Epoch 4/30 [Train]: Starting...
Epoch 4/30 [Val  ]: Starting...
Epoch 4/30: Train Loss = 0.1383, Val Loss = 0.1333
Best model found! Validation Loss: 0.1333
Epoch 5/30 [Train]: Starting...
Epoch 5/30 [Val  ]: Starting...
Epoch 5/30: Train Loss = 0.1363, Val Loss = 0.1325
Best model found! Validation Loss: 0.1325
Epoch 6/30 [Train]: Starting...
Epoch 6/30 [Val  ]: Starting...
Epoch 6/30: Train Loss = 0.1347, Val Loss = 0.1298
Best model found! Validation Loss: 0.1298
Epoch 7/30 [Train]: Starting...
Epoch 7/30 [Val  ]: Starting...
Epoch 7/30: Train Loss = 0.1334, Val Loss = 0.1281
Best model found! Validation Loss: 0.1281
Epoch 8/30 [Train]: Starting...
Epoch 8/30 [Val  ]: Starting...
Epoch 8/30: Train Loss = 0.1323, Val Loss = 0.1290
Epoch 9/30 [Train]: Starting...
Epoch 9/30 [Val  ]: Starting...
Epoch 9/30: Train Loss = 0.1315, Val Loss = 0.1278
Best model found! Validation Loss: 0.1278
Epoch 10/30 [Train]: Starting...
Epoch 10/30 [Val  ]: Starting...
Epoch 10/30: Train Loss = 0.1307, Val Loss = 0.1263
Best model found! Validation Loss: 0.1263
Epoch 11/30 [Train]: Starting...
Epoch 11/30 [Val  ]: Starting...
Epoch 11/30: Train Loss = 0.1300, Val Loss = 0.1262
Best model found! Validation Loss: 0.1262
Epoch 12/30 [Train]: Starting...
Epoch 12/30 [Val  ]: Starting...
Epoch 12/30: Train Loss = 0.1294, Val Loss = 0.1256
Best model found! Validation Loss: 0.1256
Epoch 13/30 [Train]: Starting...
Epoch 13/30 [Val  ]: Starting...
Epoch 13/30: Train Loss = 0.1287, Val Loss = 0.1251
Best model found! Validation Loss: 0.1251
Epoch 14/30 [Train]: Starting...
Epoch 14/30 [Val  ]: Starting...
Epoch 14/30: Train Loss = 0.1281, Val Loss = 0.1254
Epoch 15/30 [Train]: Starting...
Epoch 15/30 [Val  ]: Starting...
Epoch 15/30: Train Loss = 0.1277, Val Loss = 0.1254
Epoch 16/30 [Train]: Starting...
Epoch 16/30 [Val  ]: Starting...
Epoch 16/30: Train Loss = 0.1272, Val Loss = 0.1248
Best model found! Validation Loss: 0.1248
Epoch 17/30 [Train]: Starting...
Epoch 17/30 [Val  ]: Starting...
Epoch 17/30: Train Loss = 0.1267, Val Loss = 0.1250
Epoch 18/30 [Train]: Starting...
Epoch 18/30 [Val  ]: Starting...
Epoch 18/30: Train Loss = 0.1263, Val Loss = 0.1246
Best model found! Validation Loss: 0.1246
Epoch 19/30 [Train]: Starting...
Epoch 19/30 [Val  ]: Starting...
Epoch 19/30: Train Loss = 0.1258, Val Loss = 0.1249
Epoch 20/30 [Train]: Starting...
Epoch 20/30 [Val  ]: Starting...
Epoch 20/30: Train Loss = 0.1255, Val Loss = 0.1244
Best model found! Validation Loss: 0.1244
Epoch 21/30 [Train]: Starting...
Epoch 21/30 [Val  ]: Starting...
Epoch 21/30: Train Loss = 0.1251, Val Loss = 0.1252
Epoch 22/30 [Train]: Starting...
Epoch 22/30 [Val  ]: Starting...
Epoch 22/30: Train Loss = 0.1248, Val Loss = 0.1240
Best model found! Validation Loss: 0.1240
Epoch 23/30 [Train]: Starting...
Epoch 23/30 [Val  ]: Starting...
Epoch 23/30: Train Loss = 0.1244, Val Loss = 0.1240
Epoch 24/30 [Train]: Starting...
Epoch 24/30 [Val  ]: Starting...
Epoch 24/30: Train Loss = 0.1239, Val Loss = 0.1245
Epoch 25/30 [Train]: Starting...
Epoch 25/30 [Val  ]: Starting...
Epoch 25/30: Train Loss = 0.1237, Val Loss = 0.1235
Best model found! Validation Loss: 0.1235
Epoch 26/30 [Train]: Starting...
Epoch 26/30 [Val  ]: Starting...
Epoch 26/30: Train Loss = 0.1232, Val Loss = 0.1234
Best model found! Validation Loss: 0.1234
Epoch 27/30 [Train]: Starting...
Epoch 27/30 [Val  ]: Starting...
Epoch 27/30: Train Loss = 0.1230, Val Loss = 0.1235
Epoch 28/30 [Train]: Starting...
Epoch 28/30 [Val  ]: Starting...
Epoch 28/30: Train Loss = 0.1227, Val Loss = 0.1230
Best model found! Validation Loss: 0.1230
Epoch 29/30 [Train]: Starting...
Epoch 29/30 [Val  ]: Starting...
Epoch 29/30: Train Loss = 0.1224, Val Loss = 0.1234
Epoch 30/30 [Train]: Starting...
Epoch 30/30 [Val  ]: Starting...
Epoch 30/30: Train Loss = 0.1220, Val Loss = 0.1233
Training complete for BATCH_SIZE=16, LEARNING_RATE=5e-05, EPOCHS=30. Evaluating on test set...
Model for this configuration saved to finetunedbroski-512.pth
============================================================

Grid Search Complete.
The configuration that yielded the best reported test loss was: BATCH_SIZE=16, LEARNING_RATE=5e-05, EPOCHS=30
Best reported Test Loss during search: 0.0000
The model saved at 'finetunedbroski-512.pth' corresponds to the results of the *last* successfully trained hyperparameter set.

###############################################################################
H치br칩k Cluster
Job 17640955 for user s5173019
Finished at: Tue May 27 23:18:50 CEST 2025

Job details:
============

Job ID                         : 17640955
Name                           : jobscript-gpu.sh
User                           : s5173019
Partition                      : gpushort
Nodes                          : v100v2gpu17
Number of Nodes                : 1
Cores                          : 8
Number of Tasks                : 1
State                          : COMPLETED  
Submit                         : 2025-05-27T21:27:31
Start                          : 2025-05-27T21:30:11
End                            : 2025-05-27T23:18:46
Reserved walltime              : 02:00:00
Used walltime                  : 01:48:35
Used CPU time                  : 01:46:58 (Efficiency: 12.31%)
% User (Computation)           : 99.66%
% System (I/O)                 :  0.34%
Total memory reserved          : 8000M
Maximum memory used            : 1.40G
Requested GPUs                 : 1
Allocated GPUs                 : v100=1
Max GPU utilization            : 27%
Max GPU memory used            : 444.00M

Acknowledgements:
=================

Please see this page for information about acknowledging H치br칩k in your publications:

https://wiki.hpc.rug.nl/habrok/introduction/scientific_output

################################################################################
