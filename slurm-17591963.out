Using device: cuda

Running grid search with BATCH_SIZE=16, LEARNING_RATE=1e-05, EPOCHS=10
Epoch 1/10 [Train]: Starting...
Epoch 1/10 [Val  ]: Starting...
Epoch 1/10: Train Loss = 0.2538, Val Loss = 0.2119
Best model found! Validation Loss: 0.2119
Epoch 2/10 [Train]: Starting...
Epoch 2/10 [Val  ]: Starting...
Epoch 2/10: Train Loss = 0.2090, Val Loss = 0.2002
Best model found! Validation Loss: 0.2002
Epoch 3/10 [Train]: Starting...
Epoch 3/10 [Val  ]: Starting...
Epoch 3/10: Train Loss = 0.2002, Val Loss = 0.1931
Best model found! Validation Loss: 0.1931
Epoch 4/10 [Train]: Starting...
Epoch 4/10 [Val  ]: Starting...
Epoch 4/10: Train Loss = 0.1945, Val Loss = 0.1884
Best model found! Validation Loss: 0.1884
Epoch 5/10 [Train]: Starting...
Epoch 5/10 [Val  ]: Starting...
Epoch 5/10: Train Loss = 0.1903, Val Loss = 0.1846
Best model found! Validation Loss: 0.1846
Epoch 6/10 [Train]: Starting...
Epoch 6/10 [Val  ]: Starting...
Epoch 6/10: Train Loss = 0.1868, Val Loss = 0.1816
Best model found! Validation Loss: 0.1816
Epoch 7/10 [Train]: Starting...
Epoch 7/10 [Val  ]: Starting...
Epoch 7/10: Train Loss = 0.1839, Val Loss = 0.1790
Best model found! Validation Loss: 0.1790
Epoch 8/10 [Train]: Starting...
Epoch 8/10 [Val  ]: Starting...
Epoch 8/10: Train Loss = 0.1813, Val Loss = 0.1765
Best model found! Validation Loss: 0.1765
Epoch 9/10 [Train]: Starting...
Epoch 9/10 [Val  ]: Starting...
Epoch 9/10: Train Loss = 0.1791, Val Loss = 0.1744
Best model found! Validation Loss: 0.1744
Epoch 10/10 [Train]: Starting...
Epoch 10/10 [Val  ]: Starting...
Epoch 10/10: Train Loss = 0.1772, Val Loss = 0.1726
Best model found! Validation Loss: 0.1726
Training complete for BATCH_SIZE=16, LEARNING_RATE=1e-05, EPOCHS=10. Evaluating on test set...
Evaluation: Starting...
Test Loss for config (BATCH_SIZE=16, LEARNING_RATE=1e-05, EPOCHS=10): 0.1734
Model for this configuration saved to finetunedbroski.pth
============================================================

Grid Search Complete.
The configuration that yielded the best reported test loss was: BATCH_SIZE=16, LEARNING_RATE=1e-05, EPOCHS=10
Best reported Test Loss during search: 0.1734
The model saved at 'finetunedbroski.pth' corresponds to the results of the *last* successfully trained hyperparameter set.

###############################################################################
H치br칩k Cluster
Job 17591963 for user s5173019
Finished at: Sun May 25 20:16:12 CEST 2025

Job details:
============

Job ID                         : 17591963
Name                           : jobscript-gpu.sh
User                           : s5173019
Partition                      : gpushort
Nodes                          : v100v2gpu18
Number of Nodes                : 1
Cores                          : 8
Number of Tasks                : 1
State                          : COMPLETED  
Submit                         : 2025-05-25T19:46:02
Start                          : 2025-05-25T19:47:52
End                            : 2025-05-25T20:16:08
Reserved walltime              : 01:00:00
Used walltime                  : 00:28:16
Used CPU time                  : 00:27:41 (Efficiency: 12.24%)
% User (Computation)           : 99.43%
% System (I/O)                 :  0.57%
Total memory reserved          : 8000M
Maximum memory used            : 1.39G
Requested GPUs                 : 1
Allocated GPUs                 : v100=1
Max GPU utilization            : 14%
Max GPU memory used            : 412.00M
Hints and tips      :
 1) The GPU utilization is low, please check if your code can be optimized,
    or if you can move your input data to fast local storage.
 *) For more information on these issues see:
    https://wiki.hpc.rug.nl/habrok/additional_information/job_hints

Acknowledgements:
=================

Please see this page for information about acknowledging H치br칩k in your publications:

https://wiki.hpc.rug.nl/habrok/introduction/scientific_output

################################################################################
