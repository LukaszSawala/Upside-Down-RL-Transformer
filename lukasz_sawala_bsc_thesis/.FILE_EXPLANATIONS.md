# Project: Upside-Down RL Transformer

This repository folder contains various scripts and models used for training, evaluating, and analyzing Upside-Down Reinforcement Learning (UDRL) and related architectures in the AntMaze environment.

> [!TIP]
> Multiple files have complex naming. Condition 5 means the self-imitation antmaze loop as described at the end of the research. Condition 4 means the antmaze models trained on all 4 datasets available. Ft stands for finetuning, eval for evaluation. In general, if a plot/file does not have "condition" or "antmaze" in it, it means it comes from the ant environment. For file explanations, read this readme.
---

## 📁 File Overview


### `0reward_testing.py`
> This script is designed to VISUALLY (!) evaluate different models in a low-reward scenario.
> It loads pre-trained models and runs them in Ant-v5 with a specified desired reward (d_r)
> and desired horizon (d_h). The models are expected to perform well even when the reward is low.
> This script was used to analyze the behavior of the models under simple conditions.
---


### `attention_mapping_DT.py` and `attention_mapping_UDRLt.py`
> This script is designed to analyze the attention mechanism of a Decision Transformer/UDRLt model.
> It samples episodes from a dataset, computes the average attention received by each token,
> and visualizes the top-k most attended tokens. The attention scores are averaged over multiple
> batches to provide a clearer picture of the model's focus during training.
> The script uses a pre-trained Decision Transformer model and processes episodes from an HDF5 file.
> The visualization helps in understanding which tokens (states, actions, rewards) the model
> pays the most attention to, which can provide insights into the model's decision-making process.
---


### `dataset_generation.py`
> This script generates a dataset for AntMaze environment using a pre-trained BERT model.
> It collects episodes with varying reward-to-go (d_r) and horizon (d_h) values.
> The dataset is saved in HDF5 format, containing observations, actions, rewards-to-go,
> time-to-go, and goal vectors.
> The dataset is used for further training or evaluation of the model in condition 5 (last) of the research.

---

### `finetuningExtraDataAntmaze.py`
> This script is designed to fine-tune AntMaze models using a dataset generated from rollouts.
> It performs a grid search over hyperparameters such as batch size, learning rate, and epochs.
> The script trains models based on the AntMazeBERTPretrainedMazeWrapper and AntMazeNNPretrainedMazeWrapper.
> The script is intended for use in the context of AntMaze environment fine-tuning,
> specifically for the last condition of the research (condition 5).

---

### `finetuningNN_maze.py` and `finetuningUDRLt_MLP_maze.py`
> This script is designed to fine-tune a pre-trained Ant NeuralNet model using an AntMaze dataset from the
> Farama Foundation (medium-diverse) (condition 2 of the research).

---


### `ft-selfimprove-rollout-lastcondition.py`
> This script implements the last condition of the research, where the model is trained
> using a dataset generated from rollouts in the AntMaze environment. This follows the logic
> of the Upside-Down RL paper, where the model is trained on a dataset collected from the environment.
> It also plots the results of the evaluation of the model after each iteration, starting from
> the model trained on all 4 of the AntMaze datasets (condition 4).

---

### `grid_dt_training.py` and `grid_nn_training.py`
> This script is designed to perform a grid search over hyperparameters for training a Decision Transformer (DT) or the NeuralNet
> model on episodic antv-5 data. It loads a dataset from an HDF5 file, samples context windows,
> and trains the DT model using different configurations of batch size, learning rate, and max length.
> The script evaluates the model on a test set and saves the best configuration based on the test loss.

---



### `grid_UDRLT_MLP_training.py`
> This script is designed to train an UDRLt-MLP model based on BERT for Ant-v5.
> It performs a grid search over hyperparameters such as batch size, learning rate, and epochs.
> The script loads the data from an HDF5 file, splits it into training, validation, and test sets,
> and trains a model using the specified hyperparameters.

---

### `grid_UDRLT_training_OPTIMIZED.py`
> Just as `grid_UDRLT_MLP_training.py`, but for the UDRLt model and containing some memory efficiency measures
---

### `k_means_rewards.py`
> This Python script was used to generate a distribution of desired reward to go (DR) across
clusters of similar states in the Ant-V5 dataset. It is not necessary for the implementation of the models
used in this project.

---

### `model_evaluation_ALL.py`
> This script evaluates various models (NeuralNet, DecisionTransformer, BERT_UDRL, BERT_MLP)  
> in the Ant-v5 environment at the same time.  
> It collects average rewards and standard error for each model across multiple episodes  
> for different desired rewards (`d_r`).

---

### `model_evaluation.py`
> Contains the actual logic used in `model_evaluation_ALL.py`, evaluating the models 1 at a time
---

### `models.py`
> All of the models used in this research (removed everything that did not make it to the final paper)

---

### `skewed_sampling_test.py`
> This script is a test file for the skewed sampling method.
> It was used to evaluate the performance of the skewed sampling method on the concatenated data.
> Due to limited improved functionality, a uniform sampler was used instead, yet this method
> of alternative sampling can be explored further to see whether it would improve training
> the DT model, used as a baseline.

---

### `transfer_eval_main.py`
> This script evaluates AntMaze models under various conditions, comparing their performance
using pre-trained models. Check transfer_eval-various_conditions.py for more details.

---

### `transfer_eval-various_conditions.py`
> This script evaluates various conditions (1-4) of AntMaze models, comparing their performance
under different configurations. It uses pre-trained models and evaluates them
in the AntMaze environment, collecting average rewards and success rates for different
desired rewards (d_r). The results are plotted for comparison.

---

### `utils.py`
> A few useful functions

---
