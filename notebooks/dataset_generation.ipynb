{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.53705551 4.75870536 5.20804495 5.30901434 4.93248319] [24.74530334 20.20824784 15.44954248 10.24149753  4.93248319] [5. 4. 3. 2. 1.]\n",
      "Keys in episode_999: ['actions', 'infos', 'observations', 'observations_data', 'removed_last_obervation', 'rewards', 'rewards_to_go', 'terminations', 'time_to_go', 'truncations']\n",
      "episode_999 Action dimensions: (1000, 8)\n",
      "Observation dimensions: (1000, 105)\n",
      "Reward dimensions: (1000,)\n",
      "Termination dimensions: (1000,)\n",
      "Truncation dimensions: (1000,)\n"
     ]
    }
   ],
   "source": [
    "# Dataset testing\n",
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "# curr_dir = os.path.dirname(os.path.abspath(__file__))\n",
    "#parent_dir = os.path.dirname(curr_dir)\n",
    "#sys.path.append(parent_dir)\n",
    "\n",
    "file_path = \"../data/external/main_data.hdf5\"\n",
    "\n",
    "# ---------------- VARIABLES TO STORE\n",
    "all_actions = []\n",
    "all_observations = []\n",
    "all_rewards_to_go = []\n",
    "all_time_to_go = []\n",
    "# -----------------------------------\n",
    "\n",
    "with h5py.File(file_path, \"r+\") as f:\n",
    "    for key in f.keys():\n",
    "        #del episode_87[\"key-id\"] removing a thing\n",
    "        \n",
    "        curr_episode = f[key]\n",
    "\n",
    "        # split observations into the useful and useless observations (1 more observation than action) if not done before\n",
    "        if \"removed_last_obervation\" not in curr_episode.keys():\n",
    "            curr_episode[\"removed_last_obervation\"] = curr_episode[\"observations\"][-1]\n",
    "            curr_episode[\"observations_data\"] = curr_episode[\"observations\"][:-1]\n",
    "\n",
    "        # Inspect data in each attribute\n",
    "        actions = curr_episode[\"actions\"][:]\n",
    "        infos = curr_episode[\"infos\"]\n",
    "        observations = curr_episode[\"observations_data\"][:]\n",
    "        rewards = curr_episode[\"rewards\"][:]\n",
    "        terminations = curr_episode[\"terminations\"][:]\n",
    "        truncations = curr_episode[\"truncations\"][:]\n",
    "\n",
    "        reward_sum = np.sum(rewards)\n",
    "        rewards_to_go = np.zeros_like(rewards)\n",
    "        time_to_go = np.zeros_like(rewards)\n",
    "        for i in range (len(rewards)):\n",
    "            rewards_to_go[i] = reward_sum\n",
    "            reward_sum -= rewards[i]\n",
    "            time_to_go[i] = len(rewards) - i\n",
    "        # save the rewards as labels\n",
    "        \n",
    "        if \"rewards_to_go\" not in curr_episode.keys():\n",
    "            curr_episode[\"rewards_to_go\"] = rewards_to_go\n",
    "            curr_episode[\"time_to_go\"] = time_to_go\n",
    "\n",
    "        # save the stuff\n",
    "        all_actions.append(actions)\n",
    "        all_observations.append(observations)\n",
    "        all_rewards_to_go.append(rewards_to_go)\n",
    "        all_time_to_go.append(time_to_go)\n",
    "        \n",
    "\n",
    "    print(rewards[-5:], rewards_to_go[-5:], time_to_go[-5:])\n",
    "    # Dimensions:\n",
    "    print(f\"Keys in {key}:\", list(curr_episode.keys()))\n",
    "    print(f\"{key} Action dimensions: {actions.shape}\")\n",
    "    print(f\"Observation dimensions: {observations.shape}\")\n",
    "    print(f\"Reward dimensions: {rewards.shape}\")\n",
    "    print(f\"Termination dimensions: {terminations.shape}\")\n",
    "    print(f\"Truncation dimensions: {truncations.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1078\n"
     ]
    }
   ],
   "source": [
    "print(len(all_actions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concatenated data saved under 'concatenated_data' in ../data/processed/concatenated_data.hdf5\n",
      "Actions shape: (999382, 8)\n",
      "Observations shape: (999382, 105)\n"
     ]
    }
   ],
   "source": [
    "# combine the data into single vectors\n",
    "all_actions = np.concatenate(all_actions, axis=0)\n",
    "all_observations = np.concatenate(all_observations, axis=0)\n",
    "all_rewards_to_go = np.concatenate(all_rewards_to_go, axis=0)\n",
    "all_time_to_go = np.concatenate(all_time_to_go, axis=0)\n",
    "\n",
    "# create a new dataset with all the values at once\n",
    "output_file_path = \"../data/processed/concatenated_data.hdf5\"\n",
    "\n",
    "with h5py.File(output_file_path, \"w\") as f:\n",
    "    group = f.create_group(\"concatenated_data\")\n",
    "\n",
    "    # Save the concatenated data into the new group\n",
    "    group.create_dataset(\"actions\", data=all_actions)\n",
    "    group.create_dataset(\"observations\", data=all_observations)\n",
    "    group.create_dataset(\"rewards_to_go\", data=all_rewards_to_go)\n",
    "    group.create_dataset(\"time_to_go\", data=all_time_to_go)\n",
    "\n",
    "print(f\"Concatenated data saved under 'concatenated_data' in {output_file_path}\")\n",
    "print(f\"Actions shape: {all_actions.shape}\")\n",
    "print(f\"Observations shape: {all_observations.shape}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
